\newpage
\section{Introduction}


\begin{itemize}
    \item Write the formula for the square loss, the zero-one loss, and the logarithmic loss.\\

        \textbf{Absolute loss}: $\ell(y, \hat{y}) = |y-\hat{y}|$\\
        \textbf{Square loss}: $\ell(y, \hat{y}) = (y-\hat{y})^2$\\
        \textbf{Zero-one loss}: $\ell(y, \hat{y}) = \begin{cases} 
            0 & \text{if } y = \hat{y}\\ 
            1 & \text{if } y \neq \hat{y}
        \end{cases}$\\
        \textbf{Logarithmic loss}: $\ell(y, \hat{y}) = \begin{cases} 
            \ln\frac{1}{\hat{y}} & \text{if } y = 1\\ 
            \ln\frac{1}{1-\hat{y}} & \text{if } y = 0 
        \end{cases}$\\

    \item What does a learning algorithm receive in input? And what does it produce in output?\\

        A \textbf{learning algorithm} receives a training set as an input and output a predictor.\\ A \textbf{training set} is a set of examples $\mathcal{S} = \{(\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_n, y_n)\}$ where $\boldsymbol{x}_i \in \mathcal{X}$ and $y_i \in \mathcal{Y}$ for $i = 1, \dots, n$. Training and test set are often prepared together, through a single round of data collection and annotation.\\ A \textbf{predictor} is a function $f: \mathcal{X} \rightarrow \mathcal{Y}$ mapping data points to labels.\\
    
    \item Write the mathematical formula defining the training error of a predictor $h$.

        $$\ell_{S}(f) = \frac{1}{n} \sum_{i=1}^n \ell(y_i, h(\boldsymbol{x}_i))$$

    \item Write the mathematical formula defining the ERM algorithm over a class $\mathcal{H}$ of predictors.
Define the main quantities occurring in the formula.\\
         
        Let $\mathcal{F}$ be a given set of predictors and $\ell$ a loss function.  
        The \textbf{ERM} (Empirical Risk Minimization) is a learning algorithm that outputs a predictor $\hat{f}$ that minimizes the training error.\\
        $$\hat{f} \in \mathop{argmin}_{f \in \mathcal{F}} \left( \ell_{S}(f) \right)$$

        ERM obviously fails when no predictor in $\mathcal{F}$  has a low test error.
        This suggests the we should run ERM with a large $\mathcal{F}$, so that there is a good chance that a predictor with low test error exists in $\mathcal{F}$.

        In order not to fail ERM, the training set should contain at least $\log_{2}|\mathcal{F}|$ distinct data points. Equivalently, $|\mathcal{F}|$ should be smaller than $2^{m}$, where $m$ is the training set size.\\

    \item Explain in words how overfitting and underfitting are defined in terms of behavior of an algorithm on training and test set.\\

        We may give specific names to the two ways of failing of ERM (i.e., returning a predictor with high test error) for a generic learning algorithm $\mathcal{A}$: 
            \begin{itemize}
                \item if $\mathcal{A}$ fails by returning predictors with high training error, then we say that $\mathcal{A}$ is \textbf{underfitting},
                \item  if $\mathcal{A}$ fails by returning predictors with low training error, then we say that $\mathcal{A}$ is \textbf{overfitting}.
            \end{itemize}
   
    \newpage
    \item  Name and describe three reasons why labels may be noisy\footnote{Overfitting often arises when labels are noisy.}.\\

        Namely, when labels $y$ are not deterministically associated with data points $\boldsymbol{x}$. Noise may occur for at least three (not mutually exclusive) reasons. 
        \begin{enumerate}
            \item \textbf{Human in the loop}: The labels are assigned by a human annotator who decides the ``true'' label for each data point. In this case, different annotators may have different opinions.
            \item \textbf{Epistemic uncertainty}: Each data point is represented by a feature vector $\boldsymbol{x}$ that does not contain enough information to uniquely determine the label.             
            \item \textbf{Aleatoric uncertainty}: The feature vector $\boldsymbol{x}$ representing a data point is obtained through noisy measurements. The label associated with a given $\boldsymbol{x}$ is then stochastic because the same $\boldsymbol{x}$ could have been generated by different data points.
        \end{enumerate}   
        Noisy labels cause overfitting because they may mislead the algorithm with regard to what is the ``true'' label for a given data point.

\end{itemize}
